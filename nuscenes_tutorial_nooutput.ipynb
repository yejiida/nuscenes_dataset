{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib==3.10.0"
      ],
      "metadata": {
        "id": "BVXw2KufWCOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4cJbm2h3AGY"
      },
      "source": [
        "# nuScenes devkit tutorial\n",
        "\n",
        "Welcome to the nuScenes tutorial. This demo assumes the database itself is available at `/data/sets/nuscenes`, and loads a mini version of the full dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2AR-hjw3AGc"
      },
      "source": [
        "## A Gentle Introduction to nuScenes\n",
        "\n",
        "In this part of the tutorial, let us go through a top-down introduction of our database. Our dataset comprises of elemental building blocks that are the following:\n",
        "\n",
        "1. `log` - Log information from which the data was extracted.\n",
        "2. `scene` - 20 second snippet of a car's journey.\n",
        "3. `sample` - An annotated snapshot of a scene at a particular timestamp.\n",
        "4. `sample_data` - Data collected from a particular sensor.\n",
        "5. `ego_pose` - Ego vehicle poses at a particular timestamp.\n",
        "6. `sensor` - A specific sensor type.\n",
        "7. `calibrated sensor` - Definition of a particular sensor as calibrated on a particular vehicle.\n",
        "8. `instance` - Enumeration of all object instance we observed.\n",
        "9. `category` - Taxonomy of object categories (e.g. vehicle, human).\n",
        "10. `attribute` - Property of an instance that can change while the category remains the same.\n",
        "11. `visibility` - Fraction of pixels visible in all the images collected from 6 different cameras.\n",
        "12. `sample_annotation` - An annotated instance of an object within our interest.\n",
        "13. `map` - Map data that is stored as binary semantic masks from a top-down view.\n",
        "\n",
        "The database schema is visualized below. For more information see the [nuScenes schema](https://github.com/nutonomy/nuscenes-devkit/blob/master/docs/schema_nuscenes.md) page.\n",
        "![](https://www.nuscenes.org/public/images/nuscenes-schema.svg)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**< nuscenes 데이터셋 정리 >**\n",
        "### 1. log\n",
        "- 한 번의 차량 주행 로그. (수집 일시, 위치, 사용 맵 등 메타 정보)\n",
        "\n",
        "### 2. scene\n",
        "- 약 20초짜리 주행 시퀀스. 전체 데이터셋은 1000개의 scene으로 구성됨.\n",
        "\n",
        "### 3. sample\n",
        "- 0.5초 간격으로 추출된 keyframe. 모든 센서 데이터가 동기화된 시점.\n",
        "→ 자율주행 perception 알고리즘에서 주요 처리 단위.\n",
        "\n",
        "### 4. sample_data\n",
        "- 특정 센서(Camera, LiDAR, Radar 등)에서 수집된 실제 데이터 파일을 참조하는 레코드.\n",
        "\n",
        "### 5. ego_pose\n",
        "- 해당 시점에서 자차(ego vehicle)의 위치(translation)와 자세(rotation) 를 전역 좌표계(global coordinate system) 기준으로 기록.\n",
        "\n",
        "### 6. sensor\n",
        "- 센서의 종류 (예: CAM_FRONT, LIDAR_TOP, RADAR_FRONT 등).\n",
        "\n",
        "### 7. calibrated_sensor\n",
        "- 특정 차량에서 보정된 센서의 좌표계 정보 (translation/rotation, intrinsic/extrinsic).\n",
        "\n",
        "### 8. instance\n",
        "- 하나의 객체 개체(entity). 예: 특정 차량 A, 특정 보행자 B.\n",
        "(같은 instance는 한 scene 내 여러 sample_annotation으로 추적 가능)\n",
        "\n",
        "### 9. category\n",
        "- 객체 분류 체계 (예: vehicle.car, human.pedestrian, traffic_cone 등).\n",
        "→ nuScenes taxonomy는 계층적 구조 (super-category.sub-category).\n",
        "\n",
        "### 10. attribute\n",
        "- 인스턴스의 동적인 상태.\n",
        "예: vehicle.moving, vehicle.stopped, pedestrian.standing, pedestrian.sitting.\n",
        "\n",
        "### 11. visibility\n",
        "- 카메라 이미지에서 객체가 보이는 정도(0–40%, 40–60%, 60–80%, 80–100%).\n",
        "\n",
        "### 12. sample_annotation\n",
        "- 특정 sample에 존재하는 객체의 3D bounding box와 속성 정보.\n",
        "(위치, 크기, category, attribute, visibility 등)\n",
        "\n",
        "### 13. map\n",
        "- nuScenes는 4개 지역(싱가포르 3곳, 보스턴 1곳)의 맵을 제공.\n",
        "맵은 top-down semantic mask (도로, 차선, 보행자 도로 등)를 포함."
      ],
      "metadata": {
        "id": "Zenm_8dW8Lc_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **데이터의 연결 구조**\n",
        "\n",
        "### 1. scene → sample → sample_data\n",
        ": 20초 주행 → 0.5초 keyframe → 센서별 데이터\n",
        "\n",
        "### 2. sample → sample_annotation → instance → category/attribute/visibility\n",
        ": 프레임에 찍힌 객체 → 주석 정보 → 어떤 객체인지 → 분류/속성\n",
        "\n",
        "### 3. sample_data → calibrated_sensor → sensor\n",
        ": 센서별 원시 데이터 → 보정값 → 센서 종류\n",
        "\n",
        "### 4. sample_data ↔ ego_pose\n",
        ": 센서 데이터마다 동기화된 자차 위치/자세\n",
        "\n",
        "### 5. log ↔ map\n",
        ": 로그 단위 주행 → 해당 지역 맵"
      ],
      "metadata": {
        "id": "L_mCcKRI9LG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **< nuscenes 센서 >**\n",
        "\n",
        "### - 카메라 6대: 360° 커버리지 (전방, 후방, 좌우, 전방좌/우)\n",
        "\n",
        "### - 라이다 1대: 360° 3D 포인트클라우드\n",
        "\n",
        "### - 레이다 5대: 전방, 후방, 좌/우 전방"
      ],
      "metadata": {
        "id": "8KOsq-p9-oyG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgTPEfuo3AGd"
      },
      "source": [
        "## Google Colab (optional)\n",
        "\n",
        "<br>\n",
        "<a href=\"https://colab.research.google.com/github/nutonomy/nuscenes-devkit/blob/master/python-sdk/tutorials/nuscenes_tutorial.ipynb\">\n",
        "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" align=\"left\">\n",
        "</a>\n",
        "<br>\n",
        "\n",
        "If you are running this notebook in Google Colab, you can uncomment the cell below and run it; everything will be set up nicely for you. Otherwise, manually set up everything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0pLlo5L3AGe"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /data/sets/nuscenes  # Make the directory to store the nuScenes dataset in.\n",
        "\n",
        "!wget https://www.nuscenes.org/data/v1.0-mini.tgz  # Download the nuScenes mini split.\n",
        "\n",
        "!tar -xf v1.0-mini.tgz -C /data/sets/nuscenes  # Uncompress the nuScenes mini split.\n",
        "\n",
        "!pip install nuscenes-devkit &> /dev/null  # Install nuScenes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvdlahBJ3AGf"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBg5GofZ3AGg"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from nuscenes.nuscenes import NuScenes\n",
        "\n",
        "nusc = NuScenes(version='v1.0-mini', dataroot='/data/sets/nuscenes', verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmCUC5oa3AGg"
      },
      "source": [
        "## A look at the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj4WVu-j3AGh"
      },
      "source": [
        "### 1. `scene`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO6XUXbL3AGh"
      },
      "source": [
        "nuScenes is a large scale database that features annotated samples across ***1000 scenes*** of approximately 20 seconds each. Let's take a look at the scenes that we have in the loaded database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJGxJsoh3AGh"
      },
      "outputs": [],
      "source": [
        "## 모든 Scene들 요약 출력 확인\n",
        "nusc.list_scenes()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3eUDydG3AGi"
      },
      "source": [
        "Let's look at a scene metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSiHtjWz3AGi"
      },
      "outputs": [],
      "source": [
        "## 1번째 Scene 선택 -> 메타 확인\n",
        "my_scene = nusc.scene[0] ## 인덱스 0 -> 첫 번째 scene\n",
        "my_scene"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "first_sample_token, last_sample_token : 시간 경계 포함"
      ],
      "metadata": {
        "id": "Bf7nCRTFDFl0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHuxpW0W3AGi"
      },
      "source": [
        "## **2. `sample`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0O4mc0X3AGi"
      },
      "source": [
        "In scenes, we annotate our data every half a second (2 Hz).\n",
        "\n",
        "We define `sample` as an ***annotated keyframe of a scene at a given timestamp***. A keyframe is a frame where the time-stamps of data from all the sensors should be very close to the time-stamp of the sample it points to.\n",
        "\n",
        "Now, let us look at the first annotated sample in this scene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "_hDYZHa23AGj"
      },
      "outputs": [],
      "source": [
        "## 1번째 scene의 1번째 샘플 토큰 -> 0.5초 간격의 keyframe 중 1번째\n",
        "first_sample_token = my_scene['first_sample_token']\n",
        "\n",
        "# The rendering command below is commented out because it tends to crash in notebooks\n",
        "# nusc.render_sample(first_sample_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0avqcaZg3AGj"
      },
      "source": [
        "Let's examine its metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "eogpvltB3AGj"
      },
      "outputs": [],
      "source": [
        "## 첫 번째 샘플 레코드 획득\n",
        "my_sample = nusc.get('sample', first_sample_token)\n",
        "my_sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXds4vKO3AGj"
      },
      "source": [
        "A useful method is  `list_sample()` which lists all related `sample_data` keyframes and `sample_annotation` associated with a `sample` which we will discuss in detail in the subsequent parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "lXAlvCHg3AGj"
      },
      "outputs": [],
      "source": [
        "## 첫 번째 샘플 레코드 시점의 모든 keyframe 데이터/주석 연결된 요소 나열\n",
        "nusc.list_sample(my_sample['token'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "keyframe용 sample_data, sample_annotation"
      ],
      "metadata": {
        "id": "yFfnF6YxEDy5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILolFOwH3AGk"
      },
      "source": [
        "## **3. `sample_data : 센서별 프레임`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARtgteYx3AGk"
      },
      "source": [
        "The nuScenes dataset contains data that is collected from a full sensor suite. Hence, for each snapshot of a scene, we provide references to a family of data that is collected from these sensors.\n",
        "\n",
        "We provide a `data` key to access these:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJ8uHIcP3AGk"
      },
      "outputs": [],
      "source": [
        "## my_sample의 센서 채널 키\n",
        "my_sample['data']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wehm6r7U3AGk"
      },
      "source": [
        "Notice that the keys are referring to the different sensors that form our sensor suite. Let's take a look at the metadata of a `sample_data` taken from `CAM_FRONT`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpPPqVlF3AGk"
      },
      "outputs": [],
      "source": [
        "sensor = 'CAM_FRONT'\n",
        "cam_front_data = nusc.get('sample_data', my_sample['data'][sensor])\n",
        "cam_front_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8X6B3WU3AGk"
      },
      "source": [
        "We can also render the `sample_data` at a particular sensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1dz4zOb3AGk"
      },
      "outputs": [],
      "source": [
        "## 카메라, LiDAR, 레이더 데이터 이미지 투영화\n",
        "nusc.render_sample_data(cam_front_data['token'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjEs-2-P3AGl"
      },
      "source": [
        "## **4. `sample_annotation`(객체 바운딩박스)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rrd_kSa3AGl"
      },
      "source": [
        "`sample_annotation` refers to any ***bounding box defining the position of an object seen in a sample***. All location data is given with respect to the global coordinate system. Let's examine an example from our `sample` above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPGhO3xQ3AGl"
      },
      "outputs": [],
      "source": [
        "my_annotation_token = my_sample['anns'][18]\n",
        "my_annotation_metadata =  nusc.get('sample_annotation', my_annotation_token)\n",
        "my_annotation_metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uaT6tzO3AGl"
      },
      "source": [
        "We can also render an annotation to have a closer look."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eu8GyOB3AGl"
      },
      "outputs": [],
      "source": [
        "## 특정 객체 박스만 크게 시각화\n",
        "nusc.render_annotation(my_annotation_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqCjPJ693AGl"
      },
      "source": [
        "## **5. `instance`(객체 개체)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx7iCOwe3AGl"
      },
      "source": [
        "Object instance are instances that need to be detected or tracked by an AV (e.g a particular vehicle, pedestrian). Let us examine an instance metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoTXIG4Z3AGl"
      },
      "outputs": [],
      "source": [
        "my_instance = nusc.instance[599]\n",
        "my_instance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQKogNc03AGl"
      },
      "source": [
        "We generally track an instance across different frames in a particular scene. However, we do not track them across different scenes. In this example, we have 16 annotated samples for this instance across a particular scene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phgsyaMZ3AGm"
      },
      "outputs": [],
      "source": [
        "## 개체가 Scene 내의 여러 frame에 걸쳐 어떻게 움직였는지\n",
        "instance_token = my_instance['token']\n",
        "nusc.render_instance(instance_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4vxLKcI3AGm"
      },
      "source": [
        "An instance record takes note of its first and last annotation token. Let's render them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUwAVPyE3AGm"
      },
      "outputs": [],
      "source": [
        "## 시작 시점 상태\n",
        "print(\"First annotated sample of this instance:\")\n",
        "nusc.render_annotation(my_instance['first_annotation_token'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MHvSUJ23AGm"
      },
      "outputs": [],
      "source": [
        "## 종료 시점 상태\n",
        "print(\"Last annotated sample of this instance\")\n",
        "nusc.render_annotation(my_instance['last_annotation_token'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJOXdPnF3AG0"
      },
      "source": [
        "## **6. `category`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeoeLcmV3AG0"
      },
      "source": [
        "A `category` is the object assignment of an annotation.  Let's look at the category table we have in our database. The table contains the taxonomy of different object categories and also list the subcategories (delineated by a period)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYmW78x43AG1"
      },
      "outputs": [],
      "source": [
        "## 카테고리 목록, 폭/길이/높이 통계\n",
        "nusc.list_categories()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tLv2EjH3AG1"
      },
      "source": [
        "A category record contains the name and the description of that particular category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61U5mRIX3AG1"
      },
      "outputs": [],
      "source": [
        "nusc.category[9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBDHEYvQ3AG1"
      },
      "source": [
        "Refer to `instructions_nuscenes.md` for the definitions of the different categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IK-dzm3V3AG1"
      },
      "source": [
        "## **7. `attribute`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltEk9uxr3AG1"
      },
      "source": [
        "An `attribute` is a property of an instance that may change throughout different parts of a scene while the category remains the same. Here we list the provided attributes and the number of annotations associated with a particular attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-FlnNu73AG2"
      },
      "outputs": [],
      "source": [
        "## 속성 분포\n",
        "nusc.list_attributes()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPGhUllI3AG2"
      },
      "source": [
        "Let's take a look at an example how an attribute may change over one scene"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyfkI3lR3AG2"
      },
      "outputs": [],
      "source": [
        "## 1개의 instance가 시간에 따라 attribute가 변하는지 추적\n",
        "\n",
        "my_instance = nusc.instance[27]\n",
        "first_token = my_instance['first_annotation_token']\n",
        "last_token = my_instance['last_annotation_token']\n",
        "\n",
        "nbr_samples = my_instance['nbr_annotations'] ## instance가 몇 번 등장? : 총 몇 개의 프레임에서?\n",
        "current_token = first_token ## 현재 탐색중인 annotation 토큰\n",
        "\n",
        "i = 0\n",
        "found_change = False ## found_change : attribute가 바뀐 적이 있는지\n",
        "\n",
        "while current_token != last_token:\n",
        "    current_ann = nusc.get('sample_annotation', current_token)\n",
        "    current_attr = nusc.get('attribute', current_ann['attribute_tokens'][0])['name']\n",
        "\n",
        "    if i == 0:\n",
        "        pass\n",
        "    elif current_attr != last_attr:## 현재 attribute랑 직전 attribute 비교\n",
        "        print(\"Changed from `{}` to `{}` at timestamp {} out of {} annotated timestamps\".format(last_attr, current_attr, i, nbr_samples))\n",
        "        found_change = True\n",
        "\n",
        "    next_token = current_ann['next'] ## 다음 annotation의 토큰(시간 순서)\n",
        "    current_token = next_token\n",
        "\n",
        "    last_attr = current_attr\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7LBiF_s3AG2"
      },
      "source": [
        "## **8. `visibility`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7T1UiZI3AG2"
      },
      "source": [
        "`visibility` is defined as the fraction of pixels of a particular annotation that are visible over the 6 camera feeds, grouped into 4 bins."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLHbKDBJ3AG2"
      },
      "outputs": [],
      "source": [
        "nusc.visibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EwZRoah3AG2"
      },
      "source": [
        "Let's look at an example `sample_annotation` with 80-100% visibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRarwQJw3AG3"
      },
      "outputs": [],
      "source": [
        "anntoken = 'a7d0722bce164f88adf03ada491ea0ba'\n",
        "visibility_token = nusc.get('sample_annotation', anntoken)['visibility_token']\n",
        "\n",
        "print(\"Visibility: {}\".format(nusc.get('visibility', visibility_token)))\n",
        "nusc.render_annotation(anntoken)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSuV7tMj3AG3"
      },
      "source": [
        "Let's look at an example `sample_annotation` with 0-40% visibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUHw7ibS3AG3"
      },
      "outputs": [],
      "source": [
        "anntoken = '9f450bf6b7454551bbbc9a4c6e74ef2e'\n",
        "visibility_token = nusc.get('sample_annotation', anntoken)['visibility_token']\n",
        "\n",
        "print(\"Visibility: {}\".format(nusc.get('visibility', visibility_token)))\n",
        "nusc.render_annotation(anntoken)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76YyMbhG3AG3"
      },
      "source": [
        "## **9. `sensor`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAcsUTGE3AG3"
      },
      "source": [
        "The nuScenes dataset consists of data collected from our full sensor suite which consists of:\n",
        "- 1 x LIDAR,\n",
        "- 5 x RADAR,\n",
        "- 6 x cameras,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "OHvO0Rld3AG3"
      },
      "outputs": [],
      "source": [
        "nusc.sensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ontkp93q3AG4"
      },
      "source": [
        "Every `sample_data` has a record on which `sensor` the data is collected from (note the \"channel\" key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "3KVbYjvp3AG4"
      },
      "outputs": [],
      "source": [
        "nusc.sample_data[10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNqCmf7Y3AG4"
      },
      "source": [
        "## **10. `calibrated_sensor`(보정 파라미터)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifKxNZoa3AG4"
      },
      "source": [
        "`calibrated_sensor` consists of the definition of a particular sensor (lidar/radar/camera) as calibrated on a particular vehicle. Let us look at an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "N17u1xGy3AG4"
      },
      "outputs": [],
      "source": [
        "nusc.calibrated_sensor[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- translation, rotation : 차량 바디 프레임 기준\n",
        "- camera_instrinsic : 카메라의 경우"
      ],
      "metadata": {
        "id": "EHRq5CAWJHgA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCfs80zb3AG4"
      },
      "source": [
        "Note that the `translation` and the `rotation` parameters are given with respect to the ego vehicle body frame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvHPh7eq3AG4"
      },
      "source": [
        "## **11. `ego_pose`(전역 좌표계 기준의 자차 위치 / 자세)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaKaO34l3AG4"
      },
      "source": [
        "`ego_pose` contains information about the location (encoded in `translation`) and the orientation (encoded in `rotation`) of the ego vehicle, with respect to the global coordinate system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaRYKER-3AG5"
      },
      "outputs": [],
      "source": [
        "nusc.ego_pose[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nusc.ego_pose[2]"
      ],
      "metadata": {
        "id": "t14cggnZJh2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdFS2LQE3AG5"
      },
      "source": [
        "Note that the number of `ego_pose` records in our loaded database is the same as the number of `sample_data` records. These two records exhibit a one-to-one correspondence. => sample_data와 1:1 대응"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1OV0Uve3AG5"
      },
      "source": [
        "## **12. `log`**\n",
        "\n",
        "The `log` table contains log information from which the data was extracted. A `log` record corresponds to one journey of our ego vehicle along a predefined route. Let's check the number of logs and the metadata of a log."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzBzWeg93AG5"
      },
      "outputs": [],
      "source": [
        "print(\"Number of `logs` in our loaded database: {}\".format(len(nusc.log)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ln1Zje363AG5"
      },
      "outputs": [],
      "source": [
        "nusc.log[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30E5E8iS3AG5"
      },
      "source": [
        "Notice that it contains a variety of information such as the date and location of the log collected. It also gives out information about the map from where the data was collected. Note that one log can contain multiple non-overlapping scenes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhQrtd8d3AG6"
      },
      "source": [
        "## **13. `map`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdbPxfpq3AG6"
      },
      "source": [
        "Map information is stored as binary semantic masks from a top-down view. Let's check the number of maps and metadata of a map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSbhfSGD3AG6"
      },
      "outputs": [],
      "source": [
        "print(\"There are {} maps masks in the loaded dataset\".format(len(nusc.map)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "17_IRg_13AG6"
      },
      "outputs": [],
      "source": [
        "nusc.map[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V87Fd6kV3AG6"
      },
      "source": [
        "## nuScenes Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iEs0QE83AG6"
      },
      "source": [
        "Let's get a bit technical.\n",
        "\n",
        "The NuScenes class holds several tables. Each table is a list of records, and each record is a dictionary. For example the first record of the category table is stored at:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-9NQrMm3AG6"
      },
      "outputs": [],
      "source": [
        "nusc.category[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nusc.category[1]"
      ],
      "metadata": {
        "id": "h5fMXbaxKp64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "딕셔너리 형태"
      ],
      "metadata": {
        "id": "e1rldGboKl7y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdgGLU1p3AG7"
      },
      "source": [
        "The category table is simple: it holds the fields `name` and `description`. It also has a `token` field, which is a unique record identifier. Since the record is a dictionary, the token can be accessed like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XruFnoTd3AG7"
      },
      "outputs": [],
      "source": [
        "cat_token = nusc.category[0]['token']\n",
        "cat_token"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat2_name = nusc.category[1]['name']\n",
        "cat2_name"
      ],
      "metadata": {
        "id": "S16i1WroKuSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMKknX9Z3AG7"
      },
      "source": [
        "If you know the `token` for any record in the DB you can retrieve the record by doing\n",
        "=> token을 알면 그 token에 해당하는 딕셔너리 가져올 수 O"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WplIl2s3AG7"
      },
      "outputs": [],
      "source": [
        "## 토큰값으로 레코드 접근\n",
        "nusc.get('category', cat_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIU3cGLj3AG7"
      },
      "source": [
        "_As you can notice, we have recovered the same record!_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRoYeoHB3AG8"
      },
      "source": [
        "OK, that was easy. Let's try something harder. Let's look at the `sample_annotation` table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atgmjWQw3AG8"
      },
      "outputs": [],
      "source": [
        "nusc.sample_annotation[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQwPSc4s3AG8"
      },
      "source": [
        "This also has a `token` field (they all do). In addition, it has several fields of the format [a-z]*\\_token, _e.g._ instance_token. These are foreign keys in database terminology, meaning they point to another table.\n",
        "Using `nusc.get()` we can grab any of these in constant time. For example, let's look at the visibility record.\n",
        ": instance_token, visibility_token, attribute_tokens는 외래키로, 다른 테이블 가리킴"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irIOCeZC3AG8"
      },
      "outputs": [],
      "source": [
        "nusc.get('visibility', nusc.sample_annotation[0]['visibility_token'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpjv_R-x3AG8"
      },
      "source": [
        "The visibility records indicate how much of an object was visible when it was annotated.\n",
        "\n",
        "Let's also grab the `instance_token`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HslNegBS3AG8"
      },
      "outputs": [],
      "source": [
        "one_instance = nusc.get('instance', nusc.sample_annotation[0]['instance_token'])\n",
        "one_instance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## nusc.get('attribute', nusc.sample_annotation[0]['attribute_tokens'])\n",
        "## attribute_tokens는 리스트 형태라서 instance_token, visibility_token처럼 사용 불가"
      ],
      "metadata": {
        "id": "WmWr6L74MUsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfngS9ib3AG8"
      },
      "source": [
        "This points to the `instance` table. This table enumerate the object _instances_ we have encountered in each\n",
        "scene. This way we can connect all annotations of a particular object.\n",
        "\n",
        "If you look carefully at the README tables, you will see that the sample_annotation table points to the instance table,\n",
        "but the instance table doesn't list all annotations that point to it.\n",
        "\n",
        "So how can we recover all sample_annotations for a particular object instance? There are two ways:\n",
        "\n",
        "1. `Use nusc.field2token()`. Let's try it:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **field2token : 역인덱스** -> 해당 instance에 해당하는 모든 sample_annotation 토큰 얻을 수 O"
      ],
      "metadata": {
        "id": "H2WZPbgVNVdK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDZx5QdA3AG9"
      },
      "outputs": [],
      "source": [
        "ann_tokens = nusc.field2token('sample_annotation', 'instance_token', one_instance['token'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc3x1ox_3AG9"
      },
      "source": [
        "This returns a list of all sample_annotation records with the `'instance_token'` == `one_instance['token']`. Let's store these in a set for now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "9DYDwIB43AG9"
      },
      "outputs": [],
      "source": [
        "ann_tokens_field2token = set(ann_tokens)\n",
        "\n",
        "ann_tokens_field2token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIWluQhK3AG9"
      },
      "source": [
        "The `nusc.field2token()` method is generic and can be used in any similar situation.\n",
        "\n",
        "2. For certain situation, we provide some reverse indices in the tables themselves. This is one such example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf7BFOwF3AG9"
      },
      "source": [
        "The instance record has a field `first_annotation_token` which points to the first annotation in time of this instance.\n",
        "Recovering this record is easy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt8Y2QfW3AG9"
      },
      "outputs": [],
      "source": [
        "ann_record = nusc.get('sample_annotation', one_instance['first_annotation_token'])\n",
        "ann_record"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3ENFG5l3AG9"
      },
      "source": [
        "Now we can traverse all annotations of this instance using the \"next\" field. Let's try it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR1a8T4M3AG-"
      },
      "outputs": [],
      "source": [
        "ann_tokens_traverse = set() ## 토큰들 저장할 집합 / set : 중복 방지\n",
        "ann_tokens_traverse.add(ann_record['token']) ## 현재 annotation 자체의 토큰\n",
        "\n",
        "while not ann_record['next'] == \"\": ## 빈 문자열 될 때까지 반복\n",
        "    ann_record = nusc.get('sample_annotation', ann_record['next']) ## 현재 주석을 next가 가리키는 주석으로 갱신\n",
        "    ann_tokens_traverse.add(ann_record['token'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOpuNlui3AG-"
      },
      "source": [
        "Finally, let's assert that we recovered the same ann_records as we did using nusc.field2token:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJ7jYQFr3AG-"
      },
      "outputs": [],
      "source": [
        "print(ann_tokens_traverse == ann_tokens_field2token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y3FiBDZ3AG-"
      },
      "source": [
        "## Reverse indexing and short-cuts\n",
        "\n",
        "The nuScenes tables are normalized, meaning that each piece of information is only given once.\n",
        "For example, there is one `map` record for each `log` record. Looking at the schema you will notice that the `map` table has a `log_token` field, but that the `log` table does not have a corresponding `map_token` field. But there are plenty of situations where you have a `log`, and want to find the corresponding `map`! So what to do? You can always use the `nusc.field2token()` method, but that is slow and inconvenient. We therefore add reverse mappings for some common situations including this one.\n",
        "\n",
        "Further, there are situations where one needs to go through several tables to get a certain piece of information.\n",
        "Consider, for example, the category name (e.g. `human.pedestrian`) of a `sample_annotation`.\n",
        "\n",
        "-----------------------------------------------\n",
        "\n",
        " **The `sample_annotation` table doesn't hold this information since the category is an instance level constant. : 객체의 category는 변하지 않는 특성 -> 같은 instance가 여러 프레임에 등장해도 category는 변하지 X -> sample_annotation에 category를 매번 중복 저장 X / instance 테이블에 category를 붙여두는 게 효율적**\n",
        "\n",
        "-----------------------------------------------\n",
        "\n",
        " Instead the `sample_annotation` table points to a record in the `instance` table. This, in turn, points to a record in the `category` table, where finally the `name` fields stores the required information.\n",
        "\n",
        "Since it is quite common to want to know the category name of an annotation, we add a `category_name` field to the `sample_annotation` table during initialization of the NuScenes class.\n",
        "\n",
        "In this section, we list the short-cuts and reverse indices that are added to the `NuScenes` class during initialization. These are all created in the `NuScenes.__make_reverse_index__()` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75wY38XF3AG-"
      },
      "source": [
        "## **Reverse indices : 역방향 포인터 추가**\n",
        "\n",
        "We add two reverse indices by default.\n",
        "* A `map_token` field is added to the `log` records.\n",
        "* The `sample` records have shortcuts to all `sample_annotations` for that record as well as `sample_data` key-frames.\n",
        "* Confer `nusc.list_sample()` method in the previous section for more details on this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uioQWV583AG-"
      },
      "source": [
        "### Shortcuts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO9s7pD73AG-"
      },
      "source": [
        "The sample_annotation table has a \"category_name\" shortcut."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmzb5bBl3AG-"
      },
      "source": [
        "_Using shortcut:_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n585VQsh3AG-"
      },
      "outputs": [],
      "source": [
        "catname = nusc.sample_annotation[0]['category_name']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY14Z2zu3AG_"
      },
      "source": [
        "_Not using shortcut:_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nboTVbHf3AG_"
      },
      "outputs": [],
      "source": [
        "ann_rec = nusc.sample_annotation[0]\n",
        "inst_rec = nusc.get('instance', ann_rec['instance_token'])\n",
        "cat_rec = nusc.get('category', inst_rec['category_token'])\n",
        "\n",
        "print(catname == cat_rec['name'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJu0ccDg3AG_"
      },
      "source": [
        "The sample_data table has \"channel\" and \"sensor_modality\" shortcuts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4axYn7_f3AG_"
      },
      "outputs": [],
      "source": [
        "# Shortcut\n",
        "channel = nusc.sample_data[0]['channel']\n",
        "\n",
        "# No shortcut\n",
        "sd_rec = nusc.sample_data[0]\n",
        "cs_record = nusc.get('calibrated_sensor', sd_rec['calibrated_sensor_token'])\n",
        "sensor_record = nusc.get('sensor', cs_record['sensor_token'])\n",
        "\n",
        "print(channel == sensor_record['channel'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_78sXovR3AG_"
      },
      "source": [
        "## **Data Visualizations**\n",
        "\n",
        "We provide list and rendering methods.\n",
        "These are meant both as convenience methods during development, and as tutorials for building your own visualization methods.\n",
        "They are implemented in the NuScenesExplorer class, with shortcuts through the NuScenes class itself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNnWzdrh3AG_"
      },
      "source": [
        "### List methods\n",
        "There are three list methods available."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XQ0pHl53AG_"
      },
      "source": [
        "1. `list_categories()` lists all categories, counts and statistics of width/length/height in meters and aspect ratio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eoGDNIf3AHA"
      },
      "outputs": [],
      "source": [
        "nusc.list_categories()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpRlrb-V3AHA"
      },
      "source": [
        "2. `list_attributes()` lists all attributes and counts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bXYErPc3AHA"
      },
      "outputs": [],
      "source": [
        "nusc.list_attributes()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RplCbCMH3AHA"
      },
      "source": [
        "3. `list_scenes()` lists all scenes in the loaded DB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dJPfA9z3AHA"
      },
      "outputs": [],
      "source": [
        "nusc.list_scenes()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whXH4ne33AHA"
      },
      "source": [
        "### Render"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qviSaYv3AHA"
      },
      "source": [
        "First, let's plot a lidar point cloud in an image. Lidar allows us to accurately map the surroundings in 3D."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_sample = nusc.sample[10]\n",
        "nusc.render_pointcloud_in_image(my_sample['token'], pointsensor_channel='LIDAR_TOP')"
      ],
      "metadata": {
        "id": "ipRA3xYRUXRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks1tcFDs3AHB"
      },
      "source": [
        "In the previous image the colors indicate the distance from the ego vehicle to each lidar point. We can also render the lidar intensity. In the following image the traffic sign ahead of us is highly reflective (yellow) and the dark vehicle on the right has low reflectivity (purple)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usXtAV9b3AHB"
      },
      "outputs": [],
      "source": [
        "nusc.render_pointcloud_in_image(my_sample['token'], pointsensor_channel='LIDAR_TOP', render_intensity=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbHpfoxg3AHB"
      },
      "source": [
        "Second, let's plot the radar point cloud for the same image. Radar is less dense than lidar, but has a much larger range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZimlfyxI3AHB"
      },
      "outputs": [],
      "source": [
        "nusc.render_pointcloud_in_image(my_sample['token'], pointsensor_channel='RADAR_FRONT')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyfoN35f3AHB"
      },
      "source": [
        "We can also plot all annotations across all sample data for that sample. Note how for radar we also plot the velocity vectors of moving objects. Some velocity vectors are outliers, which can be filtered using the settings in RadarPointCloud.from_file()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFlCzmAS3AHB"
      },
      "outputs": [],
      "source": [
        "my_sample = nusc.sample[20]\n",
        "\n",
        "# The rendering command below is commented out because it may crash in notebooks\n",
        "# nusc.render_sample(my_sample['token'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-6Nf_WZ3AHC"
      },
      "source": [
        "Or if we only want to render a particular sensor, we can specify that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cod7SNVN3AHC"
      },
      "outputs": [],
      "source": [
        "nusc.render_sample_data(my_sample['data']['CAM_FRONT'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my2_sample = nusc.sample[10]\n",
        "nusc.render_sample_data(my2_sample['data']['CAM_FRONT'])"
      ],
      "metadata": {
        "id": "Lkae_kVXW_xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onJeUSGN3AHC"
      },
      "source": [
        "Additionally we can aggregate the point clouds from multiple sweeps to get a denser point cloud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTeVpRGm3AHC"
      },
      "outputs": [],
      "source": [
        "nusc.render_sample_data(my_sample['data']['LIDAR_TOP'], nsweeps=5, underlay_map=True)\n",
        "nusc.render_sample_data(my_sample['data']['RADAR_FRONT'], nsweeps=5, underlay_map=True)\n",
        "\n",
        "## nsweeps == 5 : 현재 시점 + 과거 4프레임 => 총 5번의 스캔 데이터 합쳐서 렌더링 / 누적한 것이므로 훨씬 밀도 높은 포인트클라우드\n",
        "## underlay_map = True : nuscenes가 제공하는 HD semantic map을 바닥에 같이 그림"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nusc.render_sample_data(my2_sample['data']['LIDAR_TOP'], nsweeps=5, underlay_map=True)\n",
        "nusc.render_sample_data(my2_sample['data']['RADAR_FRONT'], nsweeps=5, underlay_map=True)"
      ],
      "metadata": {
        "id": "LTk6uY3GXU28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFzbuqpF3AHC"
      },
      "source": [
        "In the radar plot above we only see very confident radar returns from two vehicles. This is due to the filter settings defined in the file `nuscenes/utils/data_classes.py`. If instead we want to disable all filters and render all returns, we can use the `disable_filters()` function. This returns a denser point cloud, but with many returns from background objects. To return to the default settings, simply call `default_filters()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ4cK_N63AHC"
      },
      "outputs": [],
      "source": [
        "from nuscenes.utils.data_classes import RadarPointCloud\n",
        "RadarPointCloud.disable_filters()\n",
        "nusc.render_sample_data(my_sample['data']['RADAR_FRONT'], nsweeps=5, underlay_map=True)\n",
        "\n",
        "RadarPointCloud.default_filters()\n",
        "\n",
        "## default_filters : confidence가 조건을 만족하는 것만 남김\n",
        "## disable_filters : 모든 filter들 꺼버림 -> Radar가 감지한 모든 return 다 보여줌 // 밀도 더 높아짐 but 잡음, 배경 리턴값들 다 포함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkPsKLPk3AHC"
      },
      "source": [
        "We can even render a specific annotation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9QG1lCj3AHD"
      },
      "outputs": [],
      "source": [
        "nusc.render_annotation(my_sample['anns'][22])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgyBT96t3AHD"
      },
      "source": [
        "Finally, we can render a full scene as a video. There are two options here:\n",
        "1. nusc.render_scene_channel() renders the video for a particular channel. (HIT ESC to exit)\n",
        "2. nusc.render_scene() renders the video for all camera channels.\n",
        "\n",
        "NOTE: These methods use OpenCV for rendering, which doesn't always play nice with IPython Notebooks. If you experience any issues please run these lines from the command line.\n",
        "\n",
        "Let's grab scene 0061, it is nice and dense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWcqMzZS3AHD"
      },
      "outputs": [],
      "source": [
        "my_scene_token = nusc.field2token('scene', 'name', 'scene-0061')[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import imageio.v2 as imageio\n",
        "from nuscenes.nuscenes import NuScenes\n",
        "\n",
        "# 1) 씬의 sample들을 순회하며 CAM_FRONT 프레임을 이미지로 저장\n",
        "def save_cam_front_frames(nusc: NuScenes, scene_token: str, out_dir=\"frames\"):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    scene = nusc.get('scene', scene_token)\n",
        "    sample_token = scene['first_sample_token']\n",
        "    idx = 0\n",
        "\n",
        "    while True:\n",
        "        sample = nusc.get('sample', sample_token)\n",
        "        sd_token = sample['data']['CAM_FRONT']  # 원하는 채널\n",
        "        out_path = os.path.join(out_dir, f\"frame_{idx:05d}.png\")\n",
        "        # 창 없이 파일로 저장 (Matplotlib 기반)\n",
        "        nusc.render_sample_data(sd_token, out_path=out_path, verbose=False)\n",
        "        if sample['next'] == \"\":\n",
        "            break\n",
        "        sample_token = sample['next']\n",
        "        idx += 1\n",
        "\n",
        "# 2) 저장된 이미지를 mp4로 합치기 (ffmpeg 설치 불필요, imageio 내장 writer 사용)\n",
        "def frames_to_video(frames_dir=\"frames\", video_path=\"scene_camfront.mp4\", fps=12):\n",
        "    # 프레임 파일 나열\n",
        "    files = sorted([os.path.join(frames_dir, f) for f in os.listdir(frames_dir) if f.endswith(\".png\")])\n",
        "    with imageio.get_writer(video_path, fps=fps) as writer:\n",
        "        for f in files:\n",
        "            writer.append_data(imageio.imread(f))\n",
        "    print(\"Saved:\", video_path)\n"
      ],
      "metadata": {
        "id": "oiUHFAbOa615"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_cam_front_frames(nusc, my_scene_token, out_dir=\"frames_camfront\")"
      ],
      "metadata": {
        "id": "cSIp6AztbCpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames_to_video(\"frames_camfront\", \"scene_camfront.mp4\", fps=12)"
      ],
      "metadata": {
        "id": "OZsqZY6sbQfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e-d0s1y3AHD"
      },
      "outputs": [],
      "source": [
        "# The rendering command below is commented out because it may crash in notebooks\n",
        "nusc.render_scene_channel(my_scene_token, 'CAM_FRONT')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxMMjYdD3AHD"
      },
      "source": [
        "There is also a method nusc.render_scene() which renders the video for all camera channels.\n",
        "This requires a high-res monitor, and is also best run outside this notebook."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, io\n",
        "from PIL import Image\n",
        "import imageio.v2 as imageio\n",
        "import numpy as np\n",
        "from nuscenes.nuscenes import NuScenes\n",
        "\n",
        "CAM_CHANNELS = ['CAM_FRONT_LEFT','CAM_FRONT','CAM_FRONT_RIGHT','CAM_BACK_LEFT','CAM_BACK','CAM_BACK_RIGHT']\n",
        "\n",
        "def get_ordered_samples(nusc: NuScenes, scene_token: str):\n",
        "    scene = nusc.get('scene', scene_token)\n",
        "    token = scene['first_sample_token']\n",
        "    tokens = []\n",
        "    while True:\n",
        "        tokens.append(token)\n",
        "        sample = nusc.get('sample', token)\n",
        "        if sample['next'] == \"\":\n",
        "            break\n",
        "        token = sample['next']\n",
        "    return tokens\n",
        "\n",
        "def render_cam_frame(nusc: NuScenes, sample_token: str, out_dir: str):\n",
        "    \"\"\"각 카메라 이미지를 파일로 저장하고, 메모리로도 불러 반환\"\"\"\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    imgs = []\n",
        "    for ch in CAM_CHANNELS:\n",
        "        sd_token = nusc.get('sample', sample_token)['data'][ch]\n",
        "        # 창 없이 파일로 바로 저장\n",
        "        out_path = os.path.join(out_dir, f\"{sample_token}_{ch}.png\")\n",
        "        nusc.render_sample_data(sd_token, out_path=out_path, verbose=False)\n",
        "        imgs.append(Image.open(out_path).convert(\"RGB\"))\n",
        "    return imgs\n",
        "\n",
        "def make_mosaic(imgs, grid=(2,3)):\n",
        "    \"\"\"6장을 2행 x 3열 모자이크로 합치기. 모든 이미지를 같은 크기로 리사이즈.\"\"\"\n",
        "    rows, cols = grid\n",
        "    # 기준 크기(가장 작은 폭/높이로 통일) 선정\n",
        "    min_w = min(im.width for im in imgs)\n",
        "    min_h = min(im.height for im in imgs)\n",
        "    resized = [im.resize((min_w, min_h), Image.BILINEAR) for im in imgs]\n",
        "    canvas = Image.new(\"RGB\", (cols*min_w, rows*min_h), (0,0,0))\n",
        "    for i, im in enumerate(resized):\n",
        "        r, c = divmod(i, cols)\n",
        "        canvas.paste(im, (c*min_w, r*min_h))\n",
        "    return canvas\n",
        "\n",
        "def export_scene_video_no_gui(nusc: NuScenes, scene_token: str, out_video=\"scene_allcams.mp4\", fps=12, tmp_dir=\"scene_frames\"):\n",
        "    os.makedirs(tmp_dir, exist_ok=True)\n",
        "    sample_tokens = get_ordered_samples(nusc, scene_token)\n",
        "    frames = []\n",
        "    for idx, st in enumerate(sample_tokens):\n",
        "        imgs = render_cam_frame(nusc, st, out_dir=tmp_dir)\n",
        "        mosaic = make_mosaic(imgs, grid=(2,3))\n",
        "        frames.append(np.array(mosaic))\n",
        "    # MP4로 저장\n",
        "    with imageio.get_writer(out_video, fps=fps) as w:\n",
        "        for fr in frames:\n",
        "            w.append_data(fr)\n",
        "    print(\"Saved:\", out_video)\n"
      ],
      "metadata": {
        "id": "qwJmqjwnbvDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_scene_video_no_gui(nusc, my_scene_token, out_video=\"scene_allcams.mp4\", fps=12, tmp_dir=\"scene_allcams_frames\")\n"
      ],
      "metadata": {
        "id": "vgqYiUr3cEWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVdMhq1B3AHD"
      },
      "outputs": [],
      "source": [
        "# The rendering command below is commented out because it may crash in notebooks\n",
        "nusc.render_scene(my_scene_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93NaAILW3AHD"
      },
      "source": [
        "Finally, let us visualize all scenes on the map for a particular location."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbYmEPu23AHE"
      },
      "outputs": [],
      "source": [
        "nusc.render_egoposes_on_map(log_location='singapore-onenorth')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}